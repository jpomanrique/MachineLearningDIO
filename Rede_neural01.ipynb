{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1jU82-Uxv3S-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() #definido q conversãao de imagen praa tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega aparte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJlOuI2ZxZm3",
        "outputId": "18baf817-3f5f-49ca-99a5-c37791c4d241"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.60MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaiWy2x30fvS",
        "outputId": "554d4799-2b0e-488e-e851-46b34f055f3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, etiquetas = next(dataiter) # images, etiquetas = dataiter.next()\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "eH0h3gwlzP8f",
        "outputId": "1639b114-b318-4c5c-fa50-c360bfc696b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac84d751790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images[0].shape) #para verificar as dimensões do tensor de cada imagen\n",
        "print(etiquetas[0].shape) #para verificar as dimensoes do tensor de cada etiqueta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97PB2VO1CIR",
        "outputId": "8e3e3543-27d5-4300-938f-f2ec2f84e484"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128)  # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64)     # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10)      # camada interna 2, 64 neurônios que se ligam a 10\n",
        "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.linear1(X))  # função de ativação da camada de entrada para a camada interna 1\n",
        "        X = F.relu(self.linear2(X))  # função de ativação da camada interna 1 para a camada interna 2\n",
        "        X = self.linear3(X)          # camada de saída, sem ativação (logits)\n",
        "        return F.log_softmax(X, dim=1)  # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "EoLy-WjV31Wn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)  # define a política de atualização dos pesos e da bias\n",
        "    inicio = time()  # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss()  # definindo o critério para calcular a perda\n",
        "    EPOCHS = 10  # número de epochs que o algoritmo rodará\n",
        "    modelo.train()  # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0  # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas\n",
        "            otimizador.zero_grad()  # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device))  # calculando a perda\n",
        "            perda_instantanea.backward()  # backpropagation\n",
        "            otimizador.step()  # atualizando os pesos e a bias\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"Epoch {} - Perda resultante: {}\".format(epoch + 1, perda_acumulada / len(trainloader)))\n",
        "        print(\"\\nTempo de treino (em minutos) =\", (time() - inicio) / 60)"
      ],
      "metadata": {
        "id": "NPUcnvZl6913"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "\n",
        "            img = imagens[i].view(1, 784)\n",
        "\n",
        "            # desativar o autograd para acelerar a validação.\n",
        "            # Grafos computacionais dinâmicos têm um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "                # output do modelo em escala logarítmica\n",
        "                logps = modelo(img.to(device))\n",
        "\n",
        "            ps = torch.exp(logps) # converte output para escala normal (lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0]) # converte o tensor em um número, no caso, o número que o modelo previu correto\n",
        "            etiqueta_pred = probab.index(max(probab))\n",
        "            etiqueta_certa = etiquetas.numpy()[i]\n",
        "            if etiqueta_certa == etiqueta_pred:  # compara a previsão com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas * 100 / conta_todas))"
      ],
      "metadata": {
        "id": "YqHTm5mJBf4W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo() #inicializa o modelo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UPsaDBhD7zl",
        "outputId": "eb99a6a5-fbdd-47ce-e176-255e9983acdf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treino(modelo, trainloader, device)\n",
        "validacao(modelo, valloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvdZT489EGik",
        "outputId": "8c0d5a4c-5259-4f5c-f511-ac40a8480406"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Perda resultante: 1.1661192041946882\n",
            "\n",
            "Tempo de treino (em minutos) = 0.15582555135091145\n",
            "Epoch 2 - Perda resultante: 0.3787644811467067\n",
            "\n",
            "Tempo de treino (em minutos) = 0.3013485829035441\n",
            "Epoch 3 - Perda resultante: 0.3112677648536432\n",
            "\n",
            "Tempo de treino (em minutos) = 0.4462945977846781\n",
            "Epoch 4 - Perda resultante: 0.2719358734484675\n",
            "\n",
            "Tempo de treino (em minutos) = 0.5797690192858378\n",
            "Epoch 5 - Perda resultante: 0.23957113474448608\n",
            "\n",
            "Tempo de treino (em minutos) = 0.7244935750961303\n",
            "Epoch 6 - Perda resultante: 0.21347380334189706\n",
            "\n",
            "Tempo de treino (em minutos) = 0.870425530274709\n",
            "Epoch 7 - Perda resultante: 0.19215167137478462\n",
            "\n",
            "Tempo de treino (em minutos) = 1.001723337173462\n",
            "Epoch 8 - Perda resultante: 0.1737820323028449\n",
            "\n",
            "Tempo de treino (em minutos) = 1.1461154222488403\n",
            "Epoch 9 - Perda resultante: 0.15847820777501634\n",
            "\n",
            "Tempo de treino (em minutos) = 1.2912672281265258\n",
            "Epoch 10 - Perda resultante: 0.14524010153435696\n",
            "\n",
            "Tempo de treino (em minutos) = 1.4299570878346761\n",
            "Total de imagens testadas = 10000\n",
            "\n",
            "Precisão do modelo = 95.89%\n"
          ]
        }
      ]
    }
  ]
}